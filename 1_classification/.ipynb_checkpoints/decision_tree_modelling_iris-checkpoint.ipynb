{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Modelling Iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Machine Learning example Scikit-learn library is used to develop machine learning model for classification problem. Here we will be implementing a simple decision tree model to classify iris plants into three species using the lengths and widths of their petals and sepals, a [classic data set](https://en.wikipedia.org/wiki/Iris_flower_data_set) in the machine learning community. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iris samples in question fall into three species: *Iris setosa*, *Iris versicolor*, and *Iris virginica*.  At first glance, the three species can look remarkably like each other, and this is especially the case for the latter two.  However, thanks to the careful measurements taken and presented by Anderson and Fisher, an individual sample may be classified with a high degree of accuracy via machine learning models if the relevant measurements are taken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Problem definition:\n",
    "Develop predictive Machine Learning model to predict (classify) Iris specirs based on four measured features: petal length,  sepal length, petal with and sepal petal. \n",
    "(See below picture to know what these represent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning model\n",
    "\n",
    "The decision tree models are the simplest form of tree-based models, and are arguably the simplest form of supervised multivariate classification models. A series of logical tests (generally in the form of boolean comparisons) are applied to the sample entries and their resulting subsets in turn to arrive at a final decision. It is very easy to visualize the decision process in a simple flowchart to trace the rational of every assignment made by a decision tree model, making it among the most interpretable of models. The are called 'white box'type of models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn\n",
    "We will be using the **Scikit-learn library** for the machine Learning example [sklearn](https://scikit-learn.org). It is the most comprehensive library of Machine Learning algoritms. It is simple and efficient library for predictive data analysis, accessible to everybody (Open Source), and reusable in various contexts, not only for scientific work. It built on NumPy, Pandas, SciPy, and matplotlib essential libraries. \n",
    "\n",
    "The following code, strongly derived from [scikit-learn's documentation](https://scikit-learn.org/stable/auto_examples/tree/plot_iris_dtc.html), shows how a simple decision tree model may be applied and visualized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's start coding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Python packages imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Jupyter notebook visualization \n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.tree import plot_tree\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Machine Learning \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data \n",
    "The iris dataset can be easily downloaded from Seaborn package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating DataFrame called df\n",
    "df = sns.load_dataset('iris') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the the data header by pandas method .head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view header of the data set\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What are the available variables describing the Iris flowers?\n",
    "\n",
    "-  How many?\n",
    "\n",
    "- Which of the columns represent the target variable? \n",
    "\n",
    "- What is the data type of the target?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get basic info about the dataset with `.info()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do yourself \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are the missing data for any record? \n",
    "\n",
    "Use `.isnull().any()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do yourself - check missing data records? \n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the dataset dimensionality?\n",
    "\n",
    "Use `.shape` method. The same as NumPy uses. See there is not a bracket here. Eghh :-( "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do yourself - check data set dimensionality\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what the variables mean! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"iris-dataset.png\" style=\"height:500px\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the dataset in the feature space.\n",
    "\n",
    "Use `Seaborn` method `.pairplot()`. Pass df as data parameter and select 'species' attribute for colloring the pair plots. \n",
    "\n",
    "    data=df\n",
    "\n",
    "    hue='species'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do yourself - visualize feature space in pairplot\n",
    "# Beware, it may take few seconds to run! \n",
    "\n",
    "sns.pairplot(data=df, hue = 'species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! What do we see? \n",
    "\n",
    "- Is the problem linear? \n",
    "\n",
    "- Which class(es) are simply separable and which classes are more difficult? \n",
    "\n",
    "- Can you guess what level of noise / uncertainty  is in the data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Data preparation (for Machine Learning modelling / or other analysis)\n",
    "\n",
    "Boring but extremely importnt step to succeed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the names of out attributes (features)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target variable are the species \n",
    "df['species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare two variables: X and y. \n",
    "\n",
    "    X .. all features\n",
    "    y .. target variable to predict based on the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = df['species']\n",
    "df1 = df.copy()\n",
    "X = df1.drop('species', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the two \n",
    "print(X.shape, target_variable.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y (target variable) need to be converted to numbers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation\n",
    "le = LabelEncoder()\n",
    "target_variable = le.fit_transform(target_variable) \n",
    "target_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# species coding? Which one is which? \n",
    "spec_codes  = pd.concat([df['species'], pd.DataFrame(target_variable)], axis=1)\n",
    "\n",
    "for col in spec_codes:\n",
    "    print(spec_codes[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now our y is ok\n",
    "y = target_variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Splitting training and testing datasets\n",
    "\n",
    "Simple concept to evaluate possible overfittng problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here simple random splitting, you know better ways \n",
    "# 90% for training, rest for testing \n",
    "X_train, X_test, y_train, y_test = train_test_split(X , y, test_size = 0.9, random_state = 42)\n",
    "\n",
    "print(\"Training set \", X_train.shape)\n",
    "print(\"Testing set \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Machine Learning model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ctreate instance of the Decition Tree\n",
    "tree = DecisionTreeClassifier(max_depth=5, min_samples_split=3, splitter='random', random_state = 42) \n",
    "\n",
    "# the hyperparametrs: max. depth, min. samples, splitter are here set by the user to these values\n",
    "# one can use Grid Search or Random Search techniques to finetune the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the model score during the training phase? \n",
    "tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do better cross-validation\n",
    "cv_tree = cross_validate(tree, X_train,y_train, cv=5, scoring='f1_weighted', return_estimator=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Prumer vazeneho F1-skore: {:.3f} a std {:.3f}'.format(\n",
    "        cv_tree['test_score'].mean(),\n",
    "        cv_tree['test_score'].std())\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfitted? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first run model predictions on separate test set!\n",
    "y_pred = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO accuracy metric explained! \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report accuracy metrics\n",
    "print(\"Classification report \\n\", classification_report(y_test,y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reminder\n",
    "for col in spec_codes:\n",
    "    print(spec_codes[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix?  A bit more interpretable result \n",
    "cm = confusion_matrix(y_test, y_pred) \n",
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(data=cm,linewidths=.5, annot=True, square = True, cmap = 'Blues')\n",
    "plt.ylabel('Reference')\n",
    "plt.xlabel('Predicted class')\n",
    "all_sample_title = 'F1-score: {0}'.format(round(f1_score(y_test, y_pred, average='weighted'), 3))\n",
    "plt.title(all_sample_title, size = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Howabout stratified sampling? \n",
    "from sklearn.model_selection import KFold\n",
    "kf5 = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "for train_index, test_index in kf5.split(X):\n",
    "    print(\"Running {} loop\".format(i))\n",
    "    # splitting \n",
    "    X_train = X.iloc[train_index]\n",
    "    X_test = X.iloc[test_index]\n",
    "    y_train = y[train_index]\n",
    "    y_test = y[test_index]\n",
    "        \n",
    "    # model training\n",
    "    tree.fit(X_train, y_train) \n",
    "    print(\"Accuracy for fold no. {} on test set: {}\".format(i, f1_score(y_test, tree.predict(X_test), average='weighted')))\n",
    "    i += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Model visualization (interpretable machine learning) \n",
    "\n",
    "Remeber Tree-based models are not blackboxes but whiteboxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the model \n",
    "figure(figsize=(13, 7), dpi=80)\n",
    "my_decision_tree = plot_tree(decision_tree=tree, feature_names = df1.columns,\n",
    "class_names =[\"setosa\", \"vercicolor\", \"verginica\"] , filled=True ,  precision=2, rounded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More **questions**: \n",
    "\n",
    "    - Howabout other ML models? \n",
    "    \n",
    "    - Would be Random Forest more suitable? \n",
    "    \n",
    "    - Would be SVM suitable? \n",
    "    \n",
    "    - Would be Artificial Neural Network suitable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
